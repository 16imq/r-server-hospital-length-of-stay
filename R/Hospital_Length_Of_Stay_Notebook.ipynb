{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital Length of Stay\n",
    "\n",
    "In order for hospitals to optimize resource allocation, it is important to predict accurately how long a newly admitted patient will stay in the hospital.\n",
    "\n",
    "This notebook takes advantage of the power of SQL Server and RevoScaleR (Microsoft R Server). The tables are all stored in a SQL Server, and most of the computations are done by loading chunks of data in-memory instead of the whole dataset.\n",
    "\n",
    "It does the following: \n",
    "\n",
    " * **Step 0: Packages and Compute Contexts**\n",
    " * **Step 1: Processing and Cleaning**\n",
    " * **Step 2: Feature Engineering**\n",
    " * **Step 3: Training and Evalutating the Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Packages and Compute Contexts\n",
    "\n",
    "#### In this step, we set up the connection string to access a SQL Server Database and load the necessary library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WARNING.\n",
    "# We recommend not using Internet Explorer as it does not support plotting, and may crash your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load package.\n",
    "library(RevoScaleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a database name and create it. \n",
    "db <- \"Hospital\"\n",
    "\n",
    "## Connect to the master database only to create a new database. Change UID and PWD if you modified them. \n",
    "connection_string <- \"Driver=SQL Server;Server=localhost;Database=master;UID=rdemo;PWD=D@tascience\"\n",
    "\n",
    "## Open a connection with SQL Server to be able to write queries with the rxExecuteSQLDDL function.\n",
    "outOdbcDS <- RxOdbcData(table = \"NewData\", connectionString = connection_string, useFastRead=TRUE)\n",
    "rxOpen(outOdbcDS, \"w\")\n",
    "\n",
    "query <- sprintf( \"if not exists(SELECT * FROM sys.databases WHERE name = '%s') CREATE DATABASE %s;\", db, db)\n",
    "\n",
    "## Create database. \n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Compute Contexts: user to input Server Name, database name, UOD and Password. \n",
    "connection_string <- sprintf(\"Driver=SQL Server;Server=localhost;Database=%s;UID=rdemo;PWD=D@tascience\", db)\n",
    "sql <- RxInSqlServer(connectionString = connection_string)\n",
    "local <- RxLocalSeq()\n",
    "\n",
    "## Open a connection with SQL Server to be able to write queries with the rxExecuteSQLDDL function in the new database.\n",
    "outOdbcDS <- RxOdbcData(table = \"NewData\", connectionString = connection_string, useFastRead=TRUE)\n",
    "rxOpen(outOdbcDS, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function below can be used to get the top n rows of a table stored on SQL Server. \n",
    "#### You can execute this cell throughout your progress by removing the comment \"#\", and inputting:\n",
    "#### - the table name.\n",
    "#### - the number of rows you want to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " display_head <- function(table_name, n_rows){\n",
    "   table_sql <- RxSqlServerData(sqlQuery = sprintf(\"SELECT TOP(%s) * FROM %s\", n_rows, table_name), connectionString = connection_string)\n",
    "   table <- rxImport(table_sql)\n",
    "   print(table)\n",
    "}\n",
    "\n",
    "# table_name <- \"insert_table_name\"\n",
    "# n_rows <- 10\n",
    "# display_head(table_name, n_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pre-Processing and Cleaning\n",
    "\n",
    "In this step, we: \n",
    "\n",
    "**1.** Upload the data set to SQL.\n",
    "\n",
    "**2.** Clean the merged data set: we replace NAs with the mode (categorical variables) or mean (continuous variables).\n",
    "\n",
    "**Input:**  Data Set LengthOfStay.csv\n",
    "\n",
    "**Output:** Cleaned raw data set LoS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the compute context to Local. \n",
    "rxSetComputeContext(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 100000, Total Rows Processed: 100000, Total Chunk Time: 2.874 seconds \n",
      "\n",
      "Elapsed time to compute low/high values and/or factor levels: 3.171 secs.\n",
      " \n",
      "Total Rows written: 100000, Total time: 9.414\n",
      "Rows Read: 100000, Total Rows Processed: 100000, Total Chunk Time: 11.803 seconds \n",
      "[1] \"Data exported to SQL\"\n"
     ]
    }
   ],
   "source": [
    "# Upload the data set to SQL.\n",
    "\n",
    "## Specify the desired column types. \n",
    "## Character and Factor are converted to nvarchar(255), Integer to Integer and Numeric to Float. \n",
    "column_types <-  c(eid = \"integer\",               \n",
    "                   vdate = \"character\",           \n",
    "                   rcount = \"integer\",        \n",
    "                   gender = \"factor\",            \n",
    "                   dialysisrenalendstage = \"factor\",             \n",
    "                   asthma = \"factor\",                \n",
    "                   irondef = \"factor\",                   \n",
    "                   pneum = \"factor\",                 \n",
    "                   substancedependence = \"factor\",                  \n",
    "                   psychologicaldisordermajor = \"factor\",             \n",
    "                   depress = \"factor\",           \n",
    "                   psychother = \"factor\",        \n",
    "                   fibrosisandother = \"factor\",          \n",
    "                   malnutrition = \"factor\",                               \n",
    "                   hemo = \"numeric\",            \n",
    "                   hematocritic = \"numeric\",           \n",
    "                   neutrophils = \"numeric\",           \n",
    "                   sodium = \"numeric\",          \n",
    "                   glucose = \"numeric\",             \n",
    "                   bloodureanitro = \"numeric\",                 \n",
    "                   creatinine = \"numeric\",                 \n",
    "                   bmi = \"numeric\",                 \n",
    "                   pulse = \"numeric\",                  \n",
    "                   respiration = \"numeric\",                  \n",
    "                   secondarydiagnosisnonicd9 = \"factor\",                   \n",
    "                   lengthofstay = \"factor\")\n",
    "\n",
    "\n",
    "## Point to the input data set while specifying the classes.\n",
    "LoS_text <- RxTextData(file = \"LengthOfStay.csv\", colClasses = column_types)\n",
    "\n",
    "## Upload the table to SQL. \n",
    "LengthOfStay_sql <- RxSqlServerData(table = \"LengthOfStay\", connectionString = connection_string)\n",
    "rxDataStep(inData = LoS_text, outFile = LengthOfStay_sql, overwrite = TRUE)\n",
    "\n",
    "print(\"Data exported to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 17, Total Rows Processed: 17, Total Chunk Time: Less than .001 seconds \n",
      "Rows Read: 10, Total Rows Processed: 10, Total Chunk Time: Less than .001 seconds \n",
      "[1] \"Data cleaned\"\n"
     ]
    }
   ],
   "source": [
    "# Clean the Merged data set: replace NAs with the mode (categorical variables) or mean (continuous variables). \n",
    "\n",
    "fill_NA_mode_mean <- function(table = \"LengthOfStay\"){\n",
    "  \n",
    "  ## Get the variables names and types. Assumption: no NA in eid. \n",
    "  data_sql <- RxSqlServerData(table = table, connectionString = connection_string)\n",
    "  col <- rxCreateColInfo(data_sql)\n",
    "  colnames <- names(col)\n",
    "  var <- colnames[!colnames %in% c(\"eid\")]\n",
    "  \n",
    "  categ_names <- c()\n",
    "  contin_names <- c()\n",
    "  for(name in var){\n",
    "    if(col[[name]]$type == \"numeric\"){\n",
    "      contin_names[length(contin_names) + 1] <- name\n",
    "    } else{\n",
    "      categ_names[length(categ_names) + 1] <- name\n",
    "    }\n",
    "  }\n",
    "   \n",
    "  ## For Categoricals: \n",
    "  ### Compute the modes and insert them in a table called Modes.\n",
    "  rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"DROP TABLE if exists Modes;\"\n",
    "                                                , sep=\"\"))\n",
    "  \n",
    "  rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"CREATE TABLE Modes\n",
    "                                                (name varchar(30),\n",
    "                                                 mode varchar(30));\"\n",
    "                                                , sep=\"\"))\n",
    "  \n",
    "  for(name in categ_names){\n",
    "    rxExecuteSQLDDL(outOdbcDS, sSQLString = sprintf(\"INSERT INTO Modes\n",
    "                                                     SELECT '%s', mode\n",
    "                                                     FROM (SELECT TOP(1) %s as mode, count(*) as cnt\n",
    "                                                           FROM %s\n",
    "                                                           GROUP BY %s \n",
    "                                                           ORDER BY cnt desc) as t;\",name, name, table, name))\n",
    "  }\n",
    " ### Import the Modes table.   \n",
    "  Modes_sql <- RxSqlServerData(table = \"Modes\", connectionString = connection_string) \n",
    "  Modes <- rxImport(Modes_sql)\n",
    "    \n",
    " ### Replace the NULL with the modes. \n",
    "  for(name in categ_names){\n",
    "    mode <- Modes[Modes$name == name ,2]\n",
    "    rxExecuteSQLDDL(outOdbcDS, sSQLString = sprintf(\"UPDATE %s\n",
    "                                                     SET %s = ISNULL(%s, '%s' )\n",
    "                                                      ;\",table, name, name, mode))\n",
    "  }\n",
    "  \n",
    "  ## For Continuous: \n",
    "  ### Compute the means and insert them in a table called Means.\n",
    "  rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"DROP TABLE if exists Means;\"\n",
    "                                                , sep=\"\"))\n",
    "  \n",
    "  rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"CREATE TABLE Means\n",
    "                                                (name varchar(30),\n",
    "                                                mean float);\"\n",
    "                                                , sep=\"\"))\n",
    "  \n",
    "  for(name in contin_names){\n",
    "    rxExecuteSQLDDL(outOdbcDS, sSQLString = sprintf(\"INSERT INTO Means\n",
    "                                                    SELECT '%s', mean\n",
    "                                                    FROM (SELECT AVG(%s) as mean\n",
    "                                                    FROM %s) as t;\",name, name, table))\n",
    "  }\n",
    "  ### Import the Means table.   \n",
    "  Means_sql <- RxSqlServerData(table = \"Means\", connectionString = connection_string) \n",
    "  Means <- rxImport(Means_sql)\n",
    "  \n",
    "  ### Replace the NULL with the means. \n",
    "  for(name in contin_names){\n",
    "    mean <- Means[Means$name == name ,2]\n",
    "    rxExecuteSQLDDL(outOdbcDS, sSQLString = sprintf(\"UPDATE %s\n",
    "                                                    SET %s = ISNULL(%s, %s )\n",
    "                                                    ;\",table, name, name, mean))\n",
    "  }\n",
    "\n",
    "}\n",
    "  \n",
    "# Apply the function to LengthOfStay. \n",
    "fill_NA_mode_mean()  \n",
    "\n",
    "print(\"Data cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "**1.** Standardize the continuous variables (Z-score).\n",
    "\n",
    "**2.** Create the variable number_of_issues: the number of preidentified medical conditions.\n",
    " \n",
    "\n",
    "**Input:** Data set before feature engineering LengthOfStay.\n",
    "\n",
    "**Output:** Data set with new features LoS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Feature Engineering Completed\"\n"
     ]
    }
   ],
   "source": [
    "# Create new features. \n",
    "# We use this opportunity to convert nvarchar(255) variables to char(1) for more efficient storage. \n",
    "\n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"DROP TABLE if exists LoS;\"\n",
    ", sep=\"\"))\n",
    "\n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\n",
    "        \"SELECT eid, vdate, rcount, CAST(gender as char(1)) AS gender,\n",
    "         CAST(dialysisrenalendstage as char(1)) AS dialysisrenalendstage, CAST(asthma as char(1)) AS asthma, \n",
    "         CAST(irondef as char(1)) AS irondef, CAST(pneum as char(1)) AS pneum, \n",
    "         CAST(substancedependence as char(1)) AS substancedependence,\n",
    "         CAST(psychologicaldisordermajor as char(1)) AS psychologicaldisordermajor,\n",
    "         CAST(depress as char(1)) AS depress, CAST(psychother as char(1)) AS psychother,\n",
    "         CAST(fibrosisandother as char(1)) AS fibrosisandother, CAST(malnutrition as char(1)) AS malnutrition,\n",
    "         (hemo - AVG(hemo) OVER())/(STDEV(hemo) OVER()) AS hemo_s,\n",
    "         (hematocritic - AVG(hematocritic) OVER())/(STDEV(hematocritic) OVER()) AS hematocritic_s,\n",
    "         (neutrophils - AVG(neutrophils) OVER())/(STDEV(neutrophils) OVER()) AS neutrophils_s,\n",
    "         (sodium - AVG(sodium) OVER())/(STDEV(sodium) OVER()) AS sodium_s,\n",
    "         (glucose - AVG(glucose) OVER())/(STDEV(glucose) OVER()) AS glucose_s,\n",
    "         (bloodureanitro - AVG(bloodureanitro) OVER())/(STDEV(bloodureanitro) OVER()) AS bloodureanitro_s,\n",
    "         (creatinine - AVG(creatinine) OVER())/(STDEV(creatinine) OVER()) AS creatinine_s,\n",
    "         (bmi - AVG(bmi) OVER())/(STDEV(bmi) OVER()) AS bmi_s,\n",
    "         (pulse - AVG(pulse) OVER())/(STDEV(pulse) OVER()) AS pulse_s,\n",
    "         (respiration - AVG(respiration) OVER())/(STDEV(respiration) OVER()) AS respiration_s,\n",
    "         CAST((CAST(dialysisrenalendstage as int) + CAST(asthma as int) + CAST(irondef as int) + CAST(pneum as int) +\n",
    "          CAST(substancedependence as int) + CAST(psychologicaldisordermajor as int) + CAST(depress as int) +\n",
    "          CAST(psychother as int) + CAST(fibrosisandother as int) + CAST(malnutrition as int)) as varchar(2)) \n",
    "         AS number_of_issues,\n",
    "         CAST(secondarydiagnosisnonicd9 as varchar(2)) AS secondarydiagnosisnonicd9, discharged, facid,\n",
    "         CAST(lengthofstay as char(1)) AS lengthofstay\n",
    "INTO LoS \n",
    "FROM LengthOfStay;\"\n",
    ", sep=\"\"))\n",
    "\n",
    "\n",
    "print(\"Feature Engineering Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3-A: Training and Evaluating the Models: Classification Approach\n",
    "\n",
    "In this step we:\n",
    "\n",
    "**1.** Split LoS into a Training LoS_Train, and a Testing set LoS_Test.  \n",
    "\n",
    "**2.** Train classification Random Forest (RF) and Gradient Boosting Trees (GBT) on LoS_Train, and save them to SQL. \n",
    "\n",
    "**3.** Score RF and GBT on LoS_Test.\n",
    "\n",
    "**Input:** Data set LoS\n",
    "\n",
    "**Output:** Random forest and GBT models saved to SQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Column information received\"\n"
     ]
    }
   ],
   "source": [
    "# Point to the SQL table with the data set for modeling. Strings will be converted to factors.\n",
    "LoS <- RxSqlServerData(table = \"LoS\", connectionString = connection_string, stringsAsFactors = T)\n",
    "\n",
    "# The target variable should be a factor for classification.\n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"ALTER TABLE LoS ALTER COLUMN lengthofstay char(1);\", sep=\"\"))\n",
    "\n",
    "# Get variable names, types, and levels for factors.\n",
    "column_info <- rxCreateColInfo(LoS)\n",
    "\n",
    "print(\"Column information received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Splitting completed\"\n"
     ]
    }
   ],
   "source": [
    "# Randomly split the data into a training set and a testing set, with a splitting % p.\n",
    "# p % goes to the training set, and the rest goes to the testing set. Default is 70%. \n",
    "\n",
    "p <- \"70\" \n",
    "\n",
    "## Open a connection with SQL Server to be able to write queries with the rxExecuteSQLDDL function.\n",
    "outOdbcDS <- RxOdbcData(table = \"NewData\", connectionString = connection_string, useFastRead=TRUE)\n",
    "rxOpen(outOdbcDS, \"w\")\n",
    "\n",
    "## Create the Train_Id table containing Lead_Id of training set. \n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"DROP TABLE if exists Train_Id;\", sep=\"\"))\n",
    "\n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = sprintf(\n",
    "  \"SELECT eid\n",
    "   INTO Train_Id\n",
    "   FROM LoS\n",
    "   WHERE ABS(CAST(BINARY_CHECKSUM(eid, NEWID()) as int)) %s < %s ;\"\n",
    "  ,\"% 100\", p ))\n",
    "\n",
    "## Point to the training set. It will be created on the fly when training models. \n",
    "LoS_Train <- RxSqlServerData(  \n",
    "  sqlQuery = \"SELECT *   \n",
    "              FROM LoS \n",
    "              WHERE eid IN (SELECT eid from Train_Id)\",\n",
    "  connectionString = connection_string, colInfo = column_info)\n",
    "\n",
    "## Point to the testing set. It will be created on the fly when testing models. \n",
    "LoS_Test <- RxSqlServerData(  \n",
    "  sqlQuery = \"SELECT *   \n",
    "              FROM LoS \n",
    "              WHERE eid NOT IN (SELECT eid from Train_Id)\",\n",
    "  connectionString = connection_string, colInfo = column_info)\n",
    "\n",
    "print(\"Splitting completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the variables to keep for the training by writing the formula.\n",
    "\n",
    "variables_all <- rxGetVarNames(LoS)\n",
    "variables_to_remove <- c(\"eid\", \"vdate\", \"discharged\")\n",
    "traning_variables <- variables_all[!(variables_all %in% c(\"lengthofstay\", variables_to_remove))]\n",
    "formula <- as.formula(paste(\"lengthofstay ~\", paste(traning_variables, collapse = \"+\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute Context is set to SQL for model training.\n",
    "rxSetComputeContext(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Training Classification RF done\"\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest.\n",
    "forest_model_class <- rxDForest(formula = formula,\n",
    "                                data = LoS_Train,\n",
    "                                nTree = 40,\n",
    "                                minSplit = 10,\n",
    "                                minBucket = 5,\n",
    "                                cp = 0.00005,\n",
    "                                seed = 5)\n",
    "\n",
    "\n",
    "print(\"Training Classification RF done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 1744772, Total Rows Processed: 1744772\n",
      "Total Rows written: 100000, Total time: 2.264\n",
      "Total Rows written: 200000, Total time: 4.482\n",
      "Total Rows written: 300000, Total time: 7.684\n",
      "Total Rows written: 400000, Total time: 9.902\n",
      "Total Rows written: 500000, Total time: 12.119\n",
      "Total Rows written: 600000, Total time: 14.462\n",
      "Total Rows written: 700000, Total time: 16.774\n",
      "Total Rows written: 800000, Total time: 19.023\n",
      "Total Rows written: 900000, Total time: 21.335\n",
      "Total Rows written: 1000000, Total time: 23.63\n",
      "Total Rows written: 1100000, Total time: 25.879\n",
      "Total Rows written: 1200000, Total time: 28.144\n",
      "Total Rows written: 1300000, Total time: 30.502\n",
      "Total Rows written: 1400000, Total time: 32.751\n",
      "Total Rows written: 1500000, Total time: 34.969\n",
      "Total Rows written: 1600000, Total time: 37.218\n",
      "Total Rows written: 1700000, Total time: 39.435\n",
      "Total Rows written: 1744772, Total time: 40.451\n",
      ", Total Chunk Time: 40.482 seconds \n",
      "[1] \"Classification RF model uploaded to SQL\"\n"
     ]
    }
   ],
   "source": [
    "# Save the Random Forest in SQL. The compute context is set to Local in order to export the model. \n",
    "rxSetComputeContext(local)\n",
    "saveRDS(forest_model_class, file = \"forest_model_class.rds\")\n",
    "forest_model_class_raw <- readBin(\"forest_model_class.rds\", \"raw\", n = file.size(\"forest_model_class.rds\"))\n",
    "forest_model_class_char <- as.character(forest_model_class_raw)\n",
    "forest_model_class_sql <- RxSqlServerData(table = \"Forest_Model_Class\", connectionString = connection_string) \n",
    "rxDataStep(inData = data.frame(x = forest_model_class_char ), outFile = forest_model_class_sql, overwrite = TRUE)\n",
    "\n",
    "# Set back the compute context to SQL.\n",
    "rxSetComputeContext(sql)\n",
    "\n",
    "print(\"Classification RF model uploaded to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Training Classification GBT done\"\n"
     ]
    }
   ],
   "source": [
    "# Train a Gradient Boosted Trees model.\n",
    "btree_model_class <- rxBTrees(formula = formula,\n",
    "                              data = LoS_Train,\n",
    "                              learningRate = 0.05,\n",
    "                              minSplit = 10,\n",
    "                              minBucket = 5,\n",
    "                              cp = 0.0005,\n",
    "                              nTree = 40,\n",
    "                              seed = 5,\n",
    "                              lossFunction = \"multinomial\")\n",
    "\n",
    "print(\"Training Classification GBT done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 811647, Total Rows Processed: 811647\n",
      "Total Rows written: 100000, Total time: 2.374\n",
      "Total Rows written: 200000, Total time: 4.638\n",
      "Total Rows written: 300000, Total time: 6.856\n",
      "Total Rows written: 400000, Total time: 9.105\n",
      "Total Rows written: 500000, Total time: 11.307\n",
      "Total Rows written: 600000, Total time: 13.541\n",
      "Total Rows written: 700000, Total time: 15.884\n",
      "Total Rows written: 800000, Total time: 18.211\n",
      "Total Rows written: 811647, Total time: 18.523\n",
      ", Total Chunk Time: 18.555 seconds \n",
      "[1] \"Classification GBT model uploaded to SQL\"\n"
     ]
    }
   ],
   "source": [
    "# Save the GBT in SQL. The Compute Context is set to Local in order to export the model. \n",
    "rxSetComputeContext(local)\n",
    "saveRDS(btree_model_class, file = \"btree_model_class.rds\")\n",
    "btree_model_class_raw <- readBin(\"btree_model_class.rds\", \"raw\", n = file.size(\"btree_model_class.rds\"))\n",
    "btree_model_class_char <- as.character(btree_model_class_raw)\n",
    "btree_model_class_sql <- RxSqlServerData(table = \"Btree_Model_Class\", connectionString = connection_string) \n",
    "rxDataStep(inData = data.frame(x = btree_model_class_char ), outFile = btree_model_class_sql, overwrite = TRUE)\n",
    "\n",
    "print(\"Classification GBT model uploaded to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multi-class classification model evaluation metrics\n",
    "\n",
    "evaluate_model_class <- function(observed, predicted, model) {\n",
    "  confusion <- table(observed, predicted)\n",
    "  num_classes <- nlevels(observed)\n",
    "  tp <- rep(0, num_classes)\n",
    "  fn <- rep(0, num_classes)\n",
    "  fp <- rep(0, num_classes)\n",
    "  tn <- rep(0, num_classes)\n",
    "  accuracy <- rep(0, num_classes)\n",
    "  precision <- rep(0, num_classes)\n",
    "  recall <- rep(0, num_classes)\n",
    "  for(i in 1:num_classes) {\n",
    "    tp[i] <- sum(confusion[i, i])\n",
    "    fn[i] <- sum(confusion[-i, i])\n",
    "    fp[i] <- sum(confusion[i, -i])\n",
    "    tn[i] <- sum(confusion[-i, -i])\n",
    "    accuracy[i] <- (tp[i] + tn[i]) / (tp[i] + fn[i] + fp[i] + tn[i])\n",
    "    precision[i] <- tp[i] / (tp[i] + fp[i])\n",
    "    recall[i] <- tp[i] / (tp[i] + fn[i])\n",
    "  }\n",
    "  overall_accuracy <- sum(tp) / sum(confusion)\n",
    "  average_accuracy <- sum(accuracy) / num_classes\n",
    "  micro_precision <- sum(tp) / (sum(tp) + sum(fp))\n",
    "  macro_precision <- sum(precision) / num_classes\n",
    "  micro_recall <- sum(tp) / (sum(tp) + sum(fn))\n",
    "  macro_recall <- sum(recall) / num_classes\n",
    "  metrics <- c(\"Overall accuracy\" = overall_accuracy,\n",
    "               \"Average accuracy\" = average_accuracy,\n",
    "               \"Micro-averaged Precision\" = micro_precision,\n",
    "               \"Macro-averaged Precision\" = macro_precision,\n",
    "               \"Micro-averaged Recall\" = micro_recall,\n",
    "               \"Macro-averaged Recall\" = macro_recall)\n",
    "  print(model)\n",
    "  print(metrics)\n",
    "  print(confusion)\n",
    "  return(metrics)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 21675, Total Rows Processed: 21675, Total Chunk Time: 0.766 seconds\n",
      "Total Rows written: 21675, Total time: 0.594\n",
      " \n",
      "Rows Read: 21675, Total Rows Processed: 21675, Total Chunk Time: 0.109 seconds \n",
      "[1] \"RF\"\n",
      "        Overall accuracy         Average accuracy Micro-averaged Precision \n",
      "               0.8355709                0.9177855                0.8355709 \n",
      "Macro-averaged Precision    Micro-averaged Recall    Macro-averaged Recall \n",
      "               0.8358130                0.8355709                0.8544421 \n",
      "        predicted\n",
      "observed    1    2    3    4\n",
      "       1 5178  233    0    0\n",
      "       2 1578 2103 1747    0\n",
      "       3    0    6 5337    0\n",
      "       4    0    0    0 5493\n",
      "[1] \"Scoring Classification RF done\"\n"
     ]
    }
   ],
   "source": [
    "# Classification Random Forest Scoring\n",
    "\n",
    "## Make Predictions, then import them into R. The observed Conversion_Flag is kept through the argument extraVarsToWrite.\n",
    "Prediction_Table_RF_Class <- RxSqlServerData(table = \"Forest_Prediction_Class\", stringsAsFactors = T, connectionString = connection_string)\n",
    "rxPredict(forest_model_class, data = LoS_Test, outData = Prediction_Table_RF_Class, overwrite = T, type = \"prob\",\n",
    "          extraVarsToWrite = c(\"lengthofstay\"))\n",
    "\n",
    "Prediction_RF_Class <- rxImport(inData = Prediction_Table_RF_Class, stringsAsFactors = T, outFile = NULL)\n",
    "\n",
    "## Compute the performance metrics of the model.\n",
    "Metrics_RF_Class <- evaluate_model_class(observed = factor(Prediction_RF_Class$lengthofstay, levels = c(\"1\",\"2\",\"3\",\"4\")),\n",
    "                                         predicted = factor(Prediction_RF_Class$lengthofstay_Pred, levels = c(\"1\",\"2\",\"3\",\"4\")),\n",
    "                                         model = \"RF\")\n",
    "\n",
    "print(\"Scoring Classification RF done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 21675, Total Rows Processed: 21675, Total Chunk Time: 0.766 seconds\n",
      "Total Rows written: 21675, Total time: 0.609\n",
      " \n",
      "Rows Read: 21675, Total Rows Processed: 21675, Total Chunk Time: 0.078 seconds \n",
      "[1] \"GBT\"\n",
      "        Overall accuracy         Average accuracy Micro-averaged Precision \n",
      "               0.8355709                0.9177855                0.8355709 \n",
      "Macro-averaged Precision    Micro-averaged Recall    Macro-averaged Recall \n",
      "               0.8358511                0.8355709                0.8755483 \n",
      "        predicted\n",
      "observed    1    2    3    4\n",
      "       1 5411    0    0    0\n",
      "       2 1809 1864 1755    0\n",
      "       3    0    0 5343    0\n",
      "       4    0    0    0 5493\n",
      "[1] \"Scoring Classification GBT done\"\n"
     ]
    }
   ],
   "source": [
    "# Classification Gradient Boosted Trees Scoring \n",
    "\n",
    "## Make Predictions, then import them into R. The observed Conversion_Flag is kept through the argument extraVarsToWrite.\n",
    "Prediction_Table_GBT_Class <- RxSqlServerData(table = \"Boosted_Prediction_Class\", stringsAsFactors = T, connectionString = connection_string)\n",
    "rxPredict(btree_model_class,data = LoS_Test, outData = Prediction_Table_GBT_Class, overwrite = T, type=\"prob\",\n",
    "          extraVarsToWrite = c(\"lengthofstay\"))\n",
    "\n",
    "Prediction_GBT_Class <- rxImport(inData = Prediction_Table_GBT_Class, stringsAsFactors = T, outFile = NULL)\n",
    "\n",
    "## Compute the performance metrics of the model.\n",
    "Metrics_GBT_Class <- evaluate_model_class(observed = factor(Prediction_GBT_Class$lengthofstay, levels = c(\"1\",\"2\",\"3\",\"4\")),\n",
    "                                          predicted = factor(Prediction_GBT_Class$lengthofstay_Pred, levels = c(\"1\",\"2\",\"3\",\"4\")),\n",
    "                                          model = \"GBT\")\n",
    "\n",
    "print(\"Scoring Classification GBT done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3-B: Training and Evaluating the Models: Regression Approach\n",
    "\n",
    "In this step we:\n",
    "\n",
    "**1.** Split LoS into a Training LoS_Train, and a Testing set LoS_Test.  \n",
    "\n",
    "**2.** Train regression Random Forest (RF) and Gradient Boosting Trees (GBT) on LoS_Train, and save them to SQL. \n",
    "\n",
    "**3.** Score RF and GBT on LoS_Test.\n",
    "\n",
    "**Input:** Data set LoS\n",
    "\n",
    "**Output:** Random forest and GBT models saved to SQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Column information received\"\n"
     ]
    }
   ],
   "source": [
    "# Point to the data set.\n",
    "LoS <- RxSqlServerData(table = \"LoS\", connectionString = connection_string, stringsAsFactors = T)\n",
    "\n",
    "# The target variable is converted to integer for regression.\n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"ALTER TABLE LoS ALTER COLUMN lengthofstay int;\", sep=\"\"))\n",
    "\n",
    "# Get the column info.\n",
    "column_info <- rxCreateColInfo(LoS)\n",
    "\n",
    "print(\"Column information received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Splitting completed\"\n"
     ]
    }
   ],
   "source": [
    "# Randomly split the data into a training set and a testing set, with a splitting % p.\n",
    "# p % goes to the training set, and the rest goes to the testing set. Default is 70%. \n",
    "\n",
    "p <- \"70\" \n",
    "\n",
    "## Open a connection with SQL Server to be able to write queries with the rxExecuteSQLDDL function.\n",
    "outOdbcDS <- RxOdbcData(table = \"NewData\", connectionString = connection_string, useFastRead=TRUE)\n",
    "rxOpen(outOdbcDS, \"w\")\n",
    "\n",
    "## Create the Train_Id table containing Lead_Id of training set. \n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = paste(\"DROP TABLE if exists Train_Id;\", sep=\"\"))\n",
    "\n",
    "rxExecuteSQLDDL(outOdbcDS, sSQLString = sprintf(\n",
    "  \"SELECT eid\n",
    "   INTO Train_Id\n",
    "   FROM LoS\n",
    "   WHERE ABS(CAST(BINARY_CHECKSUM(eid, NEWID()) as int)) %s < %s ;\"\n",
    "  ,\"% 100\", p ))\n",
    "\n",
    "## Point to the training set. It will be created on the fly when training models. \n",
    "LoS_Train <- RxSqlServerData(  \n",
    "  sqlQuery = \"SELECT *   \n",
    "              FROM LoS \n",
    "              WHERE eid IN (SELECT eid from Train_Id)\",\n",
    "  connectionString = connection_string, colInfo = column_info)\n",
    "\n",
    "## Point to the testing set. It will be created on the fly when testing models. \n",
    "LoS_Test <- RxSqlServerData(  \n",
    "  sqlQuery = \"SELECT *   \n",
    "              FROM LoS \n",
    "              WHERE eid NOT IN (SELECT eid from Train_Id)\",\n",
    "  connectionString = connection_string, colInfo = column_info)\n",
    "\n",
    "print(\"Splitting completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute Context is set to SQL for model training.\n",
    "rxSetComputeContext(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Training Regression RF done\"\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest.\n",
    "forest_model_reg <- rxDForest(formula = formula,\n",
    "                              data = LoS_Train,\n",
    "                              nTree = 40,\n",
    "                              minSplit = 10,\n",
    "                              minBucket = 5,\n",
    "                              cp = 0.00005,\n",
    "                              seed = 5)\n",
    "\n",
    "print(\"Training Regression RF done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 1075729, Total Rows Processed: 1075729\n",
      "Total Rows written: 100000, Total time: 2.14\n",
      "Total Rows written: 200000, Total time: 4.342\n",
      "Total Rows written: 300000, Total time: 6.529\n",
      "Total Rows written: 400000, Total time: 8.731\n",
      "Total Rows written: 500000, Total time: 11.027\n",
      "Total Rows written: 600000, Total time: 13.292\n",
      "Total Rows written: 700000, Total time: 15.51\n",
      "Total Rows written: 800000, Total time: 17.712\n",
      "Total Rows written: 900000, Total time: 19.898\n",
      "Total Rows written: 1000000, Total time: 22.101\n",
      "Total Rows written: 1075729, Total time: 23.788\n",
      ", Total Chunk Time: 23.850 seconds \n",
      "[1] \"RF Regression model uploaded to SQL\"\n"
     ]
    }
   ],
   "source": [
    "# Save the Random Forest in SQL. The compute context is set to Local in order to export the model. \n",
    "rxSetComputeContext(local)\n",
    "saveRDS(forest_model_reg, file = \"forest_model_reg.rds\")\n",
    "forest_model_reg_raw <- readBin(\"forest_model_reg.rds\", \"raw\", n = file.size(\"forest_model_reg.rds\"))\n",
    "forest_model_reg_char <- as.character(forest_model_reg_raw)\n",
    "forest_model_reg_sql <- RxSqlServerData(table = \"Forest_Model_Reg\", connectionString = connection_string) \n",
    "rxDataStep(inData = data.frame(x = forest_model_reg_char ), outFile = forest_model_reg_sql, overwrite = TRUE)\n",
    "\n",
    "# Set back the compute context to SQL.\n",
    "rxSetComputeContext(sql)\n",
    "\n",
    "print(\"RF Regression model uploaded to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Training Regression GBT done\"\n"
     ]
    }
   ],
   "source": [
    "# Train the GBT.\n",
    "btree_model_reg <- rxBTrees(formula = formula,\n",
    "                            data = LoS_Train,\n",
    "                            learningRate = 0.05,\n",
    "                            minSplit = 10,\n",
    "                            minBucket = 5,\n",
    "                            cp = 0.0005,\n",
    "                            nTree = 40,\n",
    "                            seed = 5,\n",
    "                            lossFunction = \"gaussian\")\n",
    "\n",
    "print(\"Training Regression GBT done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 800762, Total Rows Processed: 800762\n",
      "Total Rows written: 100000, Total time: 2.343\n",
      "Total Rows written: 200000, Total time: 5.685\n",
      "Total Rows written: 300000, Total time: 7.888\n",
      "Total Rows written: 400000, Total time: 10.231\n",
      "Total Rows written: 500000, Total time: 12.417\n",
      "Total Rows written: 600000, Total time: 14.651\n",
      "Total Rows written: 700000, Total time: 16.947\n",
      "Total Rows written: 800000, Total time: 19.196\n",
      "Total Rows written: 800762, Total time: 19.259\n",
      ", Total Chunk Time: 19.275 seconds \n",
      "[1] \"GBT Regression model uploaded to SQL\"\n"
     ]
    }
   ],
   "source": [
    "# Save the GBT in SQL. The Compute Context is set to Local in order to export the model. \n",
    "rxSetComputeContext(local)\n",
    "saveRDS(btree_model_reg, file = \"btree_model_reg.rds\")\n",
    "btree_model_reg_raw <- readBin(\"btree_model_reg.rds\", \"raw\", n = file.size(\"btree_model_reg.rds\"))\n",
    "btree_model_reg_char <- as.character(btree_model_reg_raw)\n",
    "btree_model_reg_sql <- RxSqlServerData(table = \"Btree_Model_Reg\", connectionString = connection_string) \n",
    "rxDataStep(inData = data.frame(x = btree_model_reg_char ), outFile = btree_model_reg_sql, overwrite = TRUE)\n",
    "\n",
    "print(\"GBT Regression model uploaded to SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that computes regression performance metrics. \n",
    "evaluate_model_reg <- function(observed, predicted, model) {\n",
    "  \n",
    "  print(model)\n",
    "  ## Regression Metrics\n",
    "  mean_observed <- mean(observed)\n",
    "  se <- (observed - predicted)^2\n",
    "  ae <- abs(observed - predicted)\n",
    "  sem <- (observed - mean_observed)^2\n",
    "  aem <- abs(observed - mean_observed)\n",
    "  mae <- mean(ae)\n",
    "  rmse <- sqrt(mean(se))\n",
    "  rae <- sum(ae) / sum(aem)\n",
    "  rse <- sum(se) / sum(sem)\n",
    "  rsq <- 1 - rse\n",
    "  \n",
    "  ## Classification Metrics when the prediction is rounded to the nearest integer. \n",
    "  predicted <- factor(round(predicted), levels = c(\"1\",\"2\",\"3\",\"4\"))\n",
    "  observed <- factor(observed, levels = c(\"1\",\"2\",\"3\",\"4\"))\n",
    "  \n",
    "  confusion <- table(observed, predicted)\n",
    "  num_classes <- nlevels(observed)\n",
    "  tp <- rep(0, num_classes)\n",
    "  fn <- rep(0, num_classes)\n",
    "  fp <- rep(0, num_classes)\n",
    "  tn <- rep(0, num_classes)\n",
    "  accuracy <- rep(0, num_classes)\n",
    "  precision <- rep(0, num_classes)\n",
    "  recall <- rep(0, num_classes)\n",
    "  for(i in 1:num_classes) {\n",
    "    tp[i] <- sum(confusion[i, i])\n",
    "    fn[i] <- sum(confusion[-i, i])\n",
    "    fp[i] <- sum(confusion[i, -i])\n",
    "    tn[i] <- sum(confusion[-i, -i])\n",
    "    accuracy[i] <- (tp[i] + tn[i]) / (tp[i] + fn[i] + fp[i] + tn[i])\n",
    "    precision[i] <- tp[i] / (tp[i] + fp[i])\n",
    "    recall[i] <- tp[i] / (tp[i] + fn[i])\n",
    "  }\n",
    "  overall_accuracy <- sum(tp) / sum(confusion)\n",
    "  average_accuracy <- sum(accuracy) / num_classes\n",
    "  micro_precision <- sum(tp) / (sum(tp) + sum(fp))\n",
    "  macro_precision <- sum(precision) / num_classes\n",
    "  micro_recall <- sum(tp) / (sum(tp) + sum(fn))\n",
    "  macro_recall <- sum(recall) / num_classes\n",
    "  \n",
    "  ## Writing all the performance metrics. \n",
    "  metrics <- c(\"Mean Absolute Error\" = mae,\n",
    "               \"Root Mean Squared Error\" = rmse,\n",
    "               \"Relative Absolute Error\" = rae,\n",
    "               \"Relative Squared Error\" = rse,\n",
    "               \"Coefficient of Determination\" = rsq,\n",
    "               \"Overall accuracy (Rounded Prediction)\" = overall_accuracy,\n",
    "               \"Average accuracy (Rounded Prediction)\" = average_accuracy,\n",
    "               \"Micro-averaged Precision (Rounded Prediction)\" = micro_precision,\n",
    "               \"Macro-averaged Precision (Rounded Prediction)\" = macro_precision,\n",
    "               \"Micro-averaged Recall (Rounded Prediction)\" = micro_recall,\n",
    "               \"Macro-averaged Recall (Rounded Prediction)\" = macro_recall)\n",
    "  print(metrics)\n",
    "  print(\"Confusion Matrix when the prediction is rounded\")\n",
    "  print(confusion)\n",
    "  return(metrics)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 21799, Total Rows Processed: 21799, Total Chunk Time: 0.797 seconds\n",
      "Total Rows written: 21799, Total time: 0.406\n",
      " \n",
      "Rows Read: 21799, Total Rows Processed: 21799, Total Chunk Time: 0.016 seconds \n",
      "[1] \"RF\"\n",
      "                          Mean Absolute Error \n",
      "                                   0.22376645 \n",
      "                      Root Mean Squared Error \n",
      "                                   0.30176265 \n",
      "                      Relative Absolute Error \n",
      "                                   0.22428126 \n",
      "                       Relative Squared Error \n",
      "                                   0.07311492 \n",
      "                 Coefficient of Determination \n",
      "                                   0.92688508 \n",
      "        Overall accuracy (Rounded Prediction) \n",
      "                                   0.83398321 \n",
      "        Average accuracy (Rounded Prediction) \n",
      "                                   0.91699161 \n",
      "Micro-averaged Precision (Rounded Prediction) \n",
      "                                   0.83398321 \n",
      "Macro-averaged Precision (Rounded Prediction) \n",
      "                                   0.83505841 \n",
      "   Micro-averaged Recall (Rounded Prediction) \n",
      "                                   0.83398321 \n",
      "   Macro-averaged Recall (Rounded Prediction) \n",
      "                                   0.84168354 \n",
      "[1] \"Confusion Matrix when the prediction is rounded\"\n",
      "        predicted\n",
      "observed    1    2    3    4\n",
      "       1 3979 1446    0    0\n",
      "       2  364 3723 1464    0\n",
      "       3    0  345 5053    0\n",
      "       4    0    0    0 5425\n",
      "[1] \"Scoring Regression RF done\"\n"
     ]
    }
   ],
   "source": [
    "# Regression Random Forest Scoring \n",
    "\n",
    "## Make Predictions, then import them into R. The observed Conversion_Flag is kept through the argument extraVarsToWrite.\n",
    "Prediction_Table_RF_Reg <- RxSqlServerData(table = \"Forest_Prediction_Reg\", stringsAsFactors = T, connectionString = connection_string)\n",
    "rxPredict(forest_model_reg, data = LoS_Test, outData = Prediction_Table_RF_Reg, overwrite = T, type = \"response\",\n",
    "          extraVarsToWrite = c(\"lengthofstay\"))\n",
    "\n",
    "Prediction_RF_Reg<- rxImport(inData = Prediction_Table_RF_Reg, stringsAsFactors = T, outFile = NULL)\n",
    "\n",
    "## Compute the performance metrics of the model.\n",
    "Metrics_RF_Reg <- evaluate_model_reg(observed = Prediction_RF_Reg$lengthofstay,\n",
    "                                    predicted = Prediction_RF_Reg$lengthofstay_Pred,\n",
    "                                    model = \"RF\")\n",
    "print(\"Scoring Regression RF done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Read: 21799, Total Rows Processed: 21799, Total Chunk Time: 0.765 seconds\n",
      "Total Rows written: 21799, Total time: 0.406\n",
      " \n",
      "Rows Read: 21799, Total Rows Processed: 21799, Total Chunk Time: 0.015 seconds \n",
      "[1] \"GBT\"\n",
      "                          Mean Absolute Error \n",
      "                                    0.6274274 \n",
      "                      Root Mean Squared Error \n",
      "                                    0.7384955 \n",
      "                      Relative Absolute Error \n",
      "                                    0.6288709 \n",
      "                       Relative Squared Error \n",
      "                                    0.4378957 \n",
      "                 Coefficient of Determination \n",
      "                                    0.5621043 \n",
      "        Overall accuracy (Rounded Prediction) \n",
      "                                    0.4212579 \n",
      "        Average accuracy (Rounded Prediction) \n",
      "                                    0.7106289 \n",
      "Micro-averaged Precision (Rounded Prediction) \n",
      "                                    0.4212579 \n",
      "Macro-averaged Precision (Rounded Prediction) \n",
      "                                    0.4182104 \n",
      "   Micro-averaged Recall (Rounded Prediction) \n",
      "                                    0.4212579 \n",
      "   Macro-averaged Recall (Rounded Prediction) \n",
      "                                          NaN \n",
      "[1] \"Confusion Matrix when the prediction is rounded\"\n",
      "        predicted\n",
      "observed    1    2    3    4\n",
      "       1    0 5425    0    0\n",
      "       2    0 5551    0    0\n",
      "       3    0 1766 3632    0\n",
      "       4    0    0 5425    0\n",
      "[1] \"Scoring regression GBT done\"\n"
     ]
    }
   ],
   "source": [
    "# Regression Gradient Boosted Trees Scoring \n",
    "\n",
    "## Make Predictions, then import them into R. The observed Conversion_Flag is kept through the argument extraVarsToWrite.\n",
    "Prediction_Table_GBT_Reg <- RxSqlServerData(table = \"Boosted_Prediction_Reg\", stringsAsFactors = T, connectionString = connection_string)\n",
    "rxPredict(btree_model_reg,data = LoS_Test, outData = Prediction_Table_GBT_Reg, overwrite = T, type=\"response\",\n",
    "          extraVarsToWrite = c(\"lengthofstay\"))\n",
    "\n",
    "Prediction_GBT_Reg <- rxImport(inData = Prediction_Table_GBT_Reg, stringsAsFactors = T, outFile = NULL)\n",
    "\n",
    "## Compute the performance metrics of the model.\n",
    "Metrics_GBT_Reg <- evaluate_model_reg(observed = Prediction_GBT_Reg$lengthofstay,\n",
    "                                      predicted = Prediction_GBT_Reg$lengthofstay_Pred,\n",
    "                                      model = \"GBT\")\n",
    "\n",
    "print(\"Scoring regression GBT done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
